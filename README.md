Title
--
(PIG-2597) Move Grunt from JavaCC to ANTLR

Abstract
--
Currently, Pig utilizes two different parser generators, JavaCC for Grunt and
ANTLR for query processing. The status is problematic because of unnecessary
complexity. Using two different parser generators in a project is confusing to
new developers. It is also burdensome for developers since they have to 
understand both frameworks and maintain both dependencies in build process.
Eventually, it hampers the development of Pig project and frustrates new 
contributors. In this project, I will re-implement Grunt, an interactive
command line interface for Pig, using ANTLR parser generator. Removing the
dependency on JavaCC will help Apache Pig project keep clean, easy to maintain
codebase. 

Benefits to Community
--
 * Implementing Grunt using ANTLR will reduce unnecessary complexity from
   having both JavaCC and ANTLR as parser generator. 
 * The new implementation will be cleaner and easier to maintain codebase. 
 * Eventually, adding features to Grunt will become easier. 

Project Goals (Deliverables)
--
During the Google Summer of Code program, I will finish

 * Design and implementation of ANTLR-based Grunt shell, 
 * Design and implementation of a test class for Grunt, and
 * Documentation of the code so that new developers can easily understand and
   change Grunt later.

The final deliverables will be in the form of patches to the trunk of Apache
Pig code repository.

If time permits, an optional goal can be replacing PigFileParser with
ANTLR-generated one, which is currently generated by JavaCC.

Design and Approach
--
Current Grunt processes inputs via `class GruntParser`. Roughly, there are two
flows:
 
 * Command processing: `processCMD(String cmd, ...)` processes CMD, any command
   supported by Grunt shell, such as `cat`, `explain`, and etc.
   These methods are called from `class PigScriptParser`, a JavaCC generated
   parser and GruntParser's superclass, as soon as being recognized.
 * Query processing: If a given string is not a command,
   `processPig(String cmd)`
   registers the query via `PigServer`, and eventually queries will be
   processed by ANTLR-generated query parser
   (`QueryLexer`, `QueryParser`, `AstValidator`, `LogicalPlanGenerator`, ...).

The new Grunt implementation will not change the query processing
part. Instead, the change will only affect `class PigScriptParser` and its 
subclass. This is because the implementation approach should be the least
intrusive way. Since Pig is widely used in many production environments,
unexpected behavior from the new Grunt shell cannot be accepted. 

Each command in Grunt will be defined in a new grammar code for ANTLR. 
But each method actually processes the command can remail as much as possible.
For example, the following grammar definition, even though it is not accurate,
can define `rm` command in Grunt:
```
remove
    :    'rm' path=ID
         {parser.processRemove($path.text, null);}
    ;
```

This way, minimal code changes and additions are required for the new 
implementation.

Additionally, replacing preprocessor with ANTLR based implementation can be
considered. `class ParameterSubstitutionPreprocessor` uses `PigFileParser`,
which is also generated by JavaCC, to substitute paramters into a query script. 

Timeline
--
 * First month (May 19 ~ June 18): Implement a test class for at least a few
   Grunt commands and parser for the commands. This will make sure the
   development is on track with a right direction. 
 * Second month (June 19 ~ July 18): Fix the problems (if any) from the first
   month. Continue adding commands to the implementation. 
 * Final month (July 19 ~ August 18): Ask the community for review and test
   code and documentation.

About Me
--
I am a fourth year PhD student in computer science at SUNY Buffalo. My main
research interest lies in distributed data processing systems. Currently I am
developing a wide-area data processing system that adapts Pig Latin script
language for describing data flows. 

I have a good understanding of how Pig processes Grunt shell commands and Pig
Latin scripts, generates logical plans, and how the logical plan is translated
into MapReduce jobs. I have experience in developing Hadoop MapReduce
applications and installing Hadoop MapReduce/HBase cluster. 

Before my graduate studies, I had been a software developer for more than 4
years. I am familiar with (distributed) version control systems such as git and
subversion. 

Contact Info
--
 * e-mail: kyungho.jeon@gmail.com
 * www: http://www.cse.buffalo.edu/~kyunghoj

